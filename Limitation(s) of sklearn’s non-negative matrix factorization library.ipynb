{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "In this notebook, I just copy the code from the previous module and explore the difference between the performance of sklearnâ€™s non-negative matrix factorization library and simple baseline or similarity-based methods in Module 3."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bad750b7eec89801"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from scipy.spatial.distance import jaccard, cosine "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T15:59:40.248285Z",
     "start_time": "2024-06-06T15:59:38.369843Z"
    }
   },
   "id": "5e9adc91086d8190",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "MV_users = pd.read_csv('movies/users.csv')\n",
    "MV_movies = pd.read_csv('movies/movies.csv')\n",
    "train = pd.read_csv('movies/train.csv')\n",
    "test = pd.read_csv('movies/test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T15:59:42.992931Z",
     "start_time": "2024-06-06T15:59:42.728869Z"
    }
   },
   "id": "e1a100010d25094f",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Data = namedtuple('Data', ['users','movies','train','test'])\n",
    "data = Data(MV_users, MV_movies, train, test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T15:59:45.393496Z",
     "start_time": "2024-06-06T15:59:45.380493Z"
    }
   },
   "id": "e82b7a2777167762",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class RecSys():\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.allusers = list(self.data.users['uID'])\n",
    "        self.allmovies = list(self.data.movies['mID'])\n",
    "        self.genres = list(self.data.movies.columns.drop(['mID', 'title', 'year']))\n",
    "        self.mid2idx = dict(zip(self.data.movies.mID, list(range(len(self.data.movies)))))\n",
    "        self.uid2idx = dict(zip(self.data.users.uID, list(range(len(self.data.users)))))\n",
    "        self.Mr = self.rating_matrix()\n",
    "        self.Mm = None\n",
    "        self.sim = np.zeros((len(self.allmovies), len(self.allmovies)))\n",
    "\n",
    "    def rating_matrix(self):\n",
    "        \"\"\"\n",
    "        Convert the rating matrix to numpy array of shape (#allusers,#allmovies)\n",
    "        \"\"\"\n",
    "        ind_movie = [self.mid2idx[x] for x in self.data.train.mID]\n",
    "        ind_user = [self.uid2idx[x] for x in self.data.train.uID]\n",
    "        rating_train = list(self.data.train.rating)\n",
    "\n",
    "        return np.array(coo_matrix((rating_train, (ind_user, ind_movie)),\n",
    "                                   shape=(len(self.allusers), len(self.allmovies))).toarray())\n",
    "\n",
    "    def predict_everything_to_3(self):\n",
    "        \"\"\"\n",
    "        Predict everything to 3 for the test data\n",
    "        \"\"\"\n",
    "        # Generate an array with 3s against all entries in test dataset\n",
    "        # your code here\n",
    "        return np.array([3] * self.data.test.shape[0])\n",
    "\n",
    "    def predict_to_user_average(self):\n",
    "        \"\"\"\n",
    "        Predict to average rating for the user.\n",
    "        Returns numpy array of shape (#users,)\n",
    "        \"\"\"\n",
    "        # Generate an array as follows:\n",
    "        # 1. Calculate all avg user rating as sum of ratings of user across all movies/number of movies whose rating > 0\n",
    "        # 2. Return the average rating of users in test data\n",
    "        # your code here\n",
    "        users = np.unique(self.allusers)\n",
    "        users_avg_rating = np.zeros((users.shape[0], 2))\n",
    "        users_avg_rating[:, 0] = users\n",
    "        res = np.zeros((self.data.test.shape[0], 2))\n",
    "        res[:, 0] = self.data.test['uID']\n",
    "        for user in users:\n",
    "            index_train = np.where(self.data.train['uID'] == user)[0]\n",
    "            selected_train = self.data.train.iloc[index_train]\n",
    "            final_train = selected_train[selected_train['rating'] > 0]\n",
    "            row = np.where(users_avg_rating[:, 0] == user)[0][0]\n",
    "            users_avg_rating[row, 1] = final_train['rating'].sum() / final_train.shape[0]\n",
    "\n",
    "        for i in range(self.data.test.shape[0]):\n",
    "            user_to_find = self.data.test.iloc[i, 0]\n",
    "            row_index = np.where(users_avg_rating[:, 0] == user_to_find)[0][0]\n",
    "            rating_of_user = users_avg_rating[row_index, 1]\n",
    "            res[i, 1] = rating_of_user\n",
    "\n",
    "        return res[:, 1]\n",
    "\n",
    "    def predict_from_sim(self, uid, mid):\n",
    "        \"\"\"\n",
    "        Predict a user rating on a movie given userID and movieID\n",
    "        \"\"\"\n",
    "        # Predict user rating as follows:\n",
    "        # 1. Get entry of user id in rating matrix\n",
    "        # 2. Get entry of movie id in sim matrix\n",
    "        # 3. Employ 1 and 2 to predict user rating of the movie\n",
    "        # your code here\n",
    "        user_ratings = self.Mr[self.uid2idx[uid]]\n",
    "        movie_similarities = self.sim[self.mid2idx[mid]]\n",
    "        \n",
    "        non_zero_indices = user_ratings > 0\n",
    "        filtered_ratings = user_ratings[non_zero_indices]\n",
    "        if movie_similarities.shape[0] == 1:\n",
    "            temp = movie_similarities.tolist()\n",
    "            movie_similarities = np.array(temp[0])\n",
    "        filtered_similarities = movie_similarities[non_zero_indices]\n",
    "        \n",
    "        if np.sum(filtered_similarities) > 0:\n",
    "            predicted_rating = np.dot(filtered_similarities, filtered_ratings) / np.sum(filtered_similarities)\n",
    "            return predicted_rating\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Predict ratings in the test data. Returns predicted rating in a numpy array of size (# of rows in testdata,)\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        prediction = []\n",
    "        for index, row in self.data.test.iterrows():\n",
    "            uid = row['uID']\n",
    "            mid = row['mID']\n",
    "            pred = self.predict_from_sim(uid, mid)\n",
    "            prediction.append(pred)\n",
    "        return np.array(prediction, dtype=float)\n",
    "\n",
    "    def rmse(self, yp):\n",
    "        yp[np.isnan(yp)] = 3  # In case there is nan values in prediction, it will impute to 3.\n",
    "        yt = np.array(self.data.test.rating)\n",
    "        return np.sqrt(((yt - yp) ** 2).mean())\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T16:00:34.464043Z",
     "start_time": "2024-06-06T16:00:34.434036Z"
    }
   },
   "id": "5bb7b3960e772295",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Creating Sample test data\n",
    "np.random.seed(42)\n",
    "sample_train = train[:30000]\n",
    "sample_test = test[:30000]\n",
    "\n",
    "\n",
    "sample_MV_users = MV_users[(MV_users.uID.isin(sample_train.uID)) | (MV_users.uID.isin(sample_test.uID))]\n",
    "sample_MV_movies = MV_movies[(MV_movies.mID.isin(sample_train.mID)) | (MV_movies.mID.isin(sample_test.mID))]\n",
    "\n",
    "\n",
    "sample_data = Data(sample_MV_users, sample_MV_movies, sample_train, sample_test)\n",
    "sample_rs = RecSys(sample_data)\n",
    "rs = RecSys(data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T16:03:50.430158Z",
     "start_time": "2024-06-06T16:03:49.680982Z"
    }
   },
   "id": "c075e3eedd8d2525",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "class MovieRecommender(RecSys):\n",
    "    def __init__(self, data, n_components=15, init='random', random_state=0):\n",
    "        super().__init__(data)\n",
    "        self.nmf_model = NMF(n_components=n_components, init=init, random_state=random_state)\n",
    "        self.W = None\n",
    "        self.H = None\n",
    "\n",
    "    def fit(self):\n",
    "        self.W = self.nmf_model.fit_transform(self.Mr)\n",
    "        self.H = self.nmf_model.components_\n",
    "\n",
    "    def predict(self):\n",
    "        return np.dot(self.W, self.H)\n",
    "\n",
    "    def calculate_rmse(self, test_data):\n",
    "        predictions = self.predict()\n",
    "        test_indices = (test_data['uID'].map(self.uid2idx).dropna(), test_data['mID'].map(self.mid2idx).dropna())\n",
    "        actual_ratings = test_data.loc[test_indices[0].index, 'rating']\n",
    "        predicted_ratings = predictions[test_indices]\n",
    "        return np.sqrt(mean_squared_error(actual_ratings, predicted_ratings))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T16:13:39.770678Z",
     "start_time": "2024-06-06T16:13:39.760676Z"
    }
   },
   "id": "71e053d54bbcbbdc",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K:\\CU boulder\\projects\\BBC news classification\\.venv\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1759: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.8732952663085833\n"
     ]
    }
   ],
   "source": [
    "recommender = MovieRecommender(data)\n",
    "recommender.fit()\n",
    "rmse = recommender.calculate_rmse(test)\n",
    "print(f\"RMSE: {rmse}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T16:14:04.015318Z",
     "start_time": "2024-06-06T16:13:55.380309Z"
    }
   },
   "id": "f6b7f77ed4586349",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "This value is much lower than RMSE in Module 3, even most of than predict_everything_to_3() with RMSE of 1.2585510334053043, which mean low performance of factorization of NMF in sklearn library.\n",
    "Given the results of the RMSE (2.8732952663085833) from the matrix factorization approach using NMF compared to the much lower RMSE values (0.98-1.25) achieved by simple baseline or similarity-based methods, it's essential to analyze why this might be the case and explore potential solutions to improve the matrix factorization model's performance.\n",
    "\n",
    "Reasons for Poor Performance with NMF\n",
    "1) Non-Negativity Constraint: NMF imposes a non-negativity constraint on both user and item matrices. This constraint may not be appropriate for all datasets, especially if the interaction data (ratings) include inherent negative values or the data is centered around zero. Movie ratings, for instance, can be more effectively modeled if negative latent factors are allowed, as they can capture dislikes or negative preferences.\n",
    "\n",
    "2) Sparsity of Data: NMF, like many other matrix factorization methods, struggles with highly sparse datasets. If many users have rated only a small number of movies, the model may find it difficult to learn meaningful latent features for the majority of users and items.\n",
    "\n",
    "3) Overfitting: With a higher number of components, NMF might overfit the training data, leading to poor generalization on unseen data (test set).\n",
    "\n",
    "4) Simplicity of Model: NMF does not incorporate any regularization terms or mechanisms to handle user bias (e.g., some users might generally give higher ratings) and item bias (e.g., some movies might generally receive higher ratings). Baseline methods typically account for these biases explicitly."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cebccfbac851212d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Suggested Fixes:\n",
    "1. Incorporate Biases: Modifying the NMF model to include user and item biases can significantly improve performance. This can be done by subtracting the global average rating, user bias, and item bias from each rating before fitting the model and adding them back to the predictions.\n",
    "\n",
    "2. Use Regularization: Adding regularization terms (like L2 regularization) to the loss function used by NMF can help prevent overfitting, especially in the case of sparse data.\n",
    "\n",
    "3. Hybrid Approaches: Combining NMF with other techniques, such as similarity-based methods or even neural networks, can help capture more complex patterns in the data. Hybrid models can leverage the strengths of each approach.\n",
    "\n",
    "4. Tuning Hyperparameters: Adjusting the number of latent factors (n_components) and the initialization parameters could yield better results. Cross-validation should be used to find the optimal configuration.\n",
    "\n",
    "5. Alternate Matrix Factorization Techniques: If NMF's non-negativity constraint is too restrictive, other matrix factorization techniques such as SVD (Singular Value Decomposition) or ALS (Alternating Least Squares) might be more appropriate, as they do not impose this constraint.\n",
    "\n",
    "6. Enhance Data Quality: Techniques to handle sparsity, like data imputation or gathering more data, can improve the model's learning ability."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec932f4f66a73d8a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "14a254c50ac1e143"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
